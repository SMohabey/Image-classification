{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine learning classificatin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author @Mohabey\n",
    "#classifying cat, dog, panda image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras import applications\n",
    "\n",
    "# Classifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2882/2882 [00:42<00:00, 67.91it/s]\n",
      "100%|████████████████████████████████████████| 153/153 [00:01<00:00, 94.07it/s]\n"
     ]
    }
   ],
   "source": [
    "categories = ['dog', 'panda', 'cat']\n",
    "X_train, X_test = [], []\n",
    "y_train, y_test = [], []\n",
    "imagePaths = []\n",
    "HEIGHT = 32\n",
    "WIDTH = 55\n",
    "N_CHANNELS = 3\n",
    "\n",
    "\n",
    "# load training data\n",
    "for k, category in enumerate(categories):\n",
    "    for f in os.listdir('./data/train/' + category):\n",
    "        imagePaths.append(['./data/train/' + category+'/'+f, k])\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in tqdm(imagePaths):\n",
    "    if 'ds_store' in imagePath[0].lower():\n",
    "        continue\n",
    "    # load the image, resize the image to be HEIGHT * WIDTH pixels (ignoring\n",
    "    # aspect ratio) and store the image in the data list\n",
    "    image = cv2.imread(imagePath[0])\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\n",
    "    X_train.append(image)\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath[1]\n",
    "    y_train.append(label)\n",
    "\n",
    "# load test data\n",
    "imagePaths = []\n",
    "for k, category in enumerate(categories):\n",
    "    for f in os.listdir('./data/test/' + category):\n",
    "        imagePaths.append(['./data/test/' + category+'/'+f, k])\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in tqdm(imagePaths):\n",
    "    if 'ds_store' in imagePath[0].lower():\n",
    "        continue\n",
    "    # load the image, resize the image to be HEIGHT * WIDTH pixels (ignoring\n",
    "    # aspect ratio) and store the image in the data list\n",
    "    image = cv2.imread(imagePath[0])\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\n",
    "    X_test.append(image)\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath[1]\n",
    "    y_test.append(label)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test  = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1deac289ec8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show images\n",
    "plt.figure(figsize=(15,2))\n",
    "plt.imshow(X_train[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data. \n",
    "#Images are numbers [0,255]. By dividing by 255 we normalize it into a range of [0,1]\n",
    "X_train = np.array(X_train) / 255\n",
    "X_test = np.array(X_test) / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a CNN, the input is always a tensor. A Tensor is a 3-D Matrix (height, width, channels). \"Channels are the colors\". \n",
    "\n",
    "#X_train = X_train.reshape(-1, 32, 55, 3)\n",
    "#X_test = X_test.reshape(-1, 32, 55, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2879, 32, 55, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape    #checking the shape of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2879,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape     #checking shape of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 32, 55, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 55, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 14, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 14, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 2, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 493,059\n",
      "Trainable params: 492,227\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "# CNN model has following layer convolution, batch, maxpool, conv, dropout, batch,maxpool,conv,max,conv,dropout,batch,maxpool\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), strides=1, padding='same', activation='relu', input_shape=X_train.shape[1:])) # this layer has 32 filters. The filter size is: (3,3)\n",
    "model.add(BatchNormalization()) # to avoid overfitting\n",
    "model.add(MaxPool2D((2,2), strides=2, padding='same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1)) # it randomly removes neurons, to avoid overfitting.\n",
    "model.add(BatchNormalization()) # BatchNormalization\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))       #since we have 3 output category\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])   #using adam optimizer and sparse_categorical_crossentropy as a loss functiom\n",
    "\n",
    "model.summary()    #Generate summary of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 12s 130ms/step - loss: 0.0596 - accuracy: 0.9802 - val_loss: 1.2203 - val_accuracy: 0.6933\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 11s 127ms/step - loss: 0.0398 - accuracy: 0.9844 - val_loss: 1.1688 - val_accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 12s 129ms/step - loss: 0.0850 - accuracy: 0.9680 - val_loss: 1.5030 - val_accuracy: 0.7133\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 0.0300 - accuracy: 0.9882 - val_loss: 1.4561 - val_accuracy: 0.6867\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 12s 128ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 1.7172 - val_accuracy: 0.7267\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 12s 131ms/step - loss: 0.0547 - accuracy: 0.9802 - val_loss: 1.3085 - val_accuracy: 0.7133\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 12s 131ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 1.0632 - val_accuracy: 0.7533\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 12s 131ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 1.0712 - val_accuracy: 0.7400\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 12s 130ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.2801 - val_accuracy: 0.7467\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 12s 130ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.9938 - val_accuracy: 0.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1deb3529088>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test)) # Running for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Neural Network Model\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Test Class\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.57      0.84      0.68        50\n",
      "       panda       0.78      0.90      0.83        50\n",
      "         cat       0.78      0.28      0.41        50\n",
      "\n",
      "    accuracy                           0.67       150\n",
      "   macro avg       0.71      0.67      0.64       150\n",
      "weighted avg       0.71      0.67      0.64       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "print(\"Classification Report Test Class\\n\")\n",
    "target_name = ['dog', 'panda', 'cat']\n",
    "print(classification_report(y_test, y_pred_classes, target_names = target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Train Class\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dog       0.87      0.99      0.93       954\n",
      "       panda       0.94      1.00      0.97       956\n",
      "         cat       1.00      0.80      0.89       969\n",
      "\n",
      "    accuracy                           0.93      2879\n",
      "   macro avg       0.93      0.93      0.93      2879\n",
      "weighted avg       0.93      0.93      0.93      2879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred_train]\n",
    "print(\"Classification Report Train Class\\n\")\n",
    "target_name = ['dog', 'panda', 'cat']\n",
    "print(classification_report(y_train, y_pred_classes, target_names = target_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 2s 18ms/step - loss: 0.2329 - accuracy: 0.9278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2328823208808899, 0.927752673625946]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9938 - accuracy: 0.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.993818759918213, 0.6733333468437195]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
